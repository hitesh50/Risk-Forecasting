
<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta name="keywords" content="remark,remarkjs,markdown,slideshow,presentation" />
    <meta name="description" content="A simple, in-browser, markdown-driven slideshow tool." />
    <title>Risk Forecasting</title>
    <link rel="stylesheet" href="./font-awesome/css/font-awesome.min.css">
    <style>
      @import url(https://fonts.googleapis.com/css?family=Droid+Serif);
      @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

      body {
        font-family: 'Droid Serif';
      }
      h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: 400;
        margin-bottom: 0;
      }
      .remark-slide-content h1 { font-size: 3em; }
      .remark-slide-content h2 { font-size: 2em; }
      .remark-slide-content h3 { font-size: 1.6em; }
      .footnote {
        position: absolute;
        bottom: 3em;
      }
      li p { line-height: 1.25em; }
      .red { color: #fa0000; }
      .green { color: green}
      .large { font-size: 2em; }
      a, a > code {
        color: #c0c8d3;
        text-decoration: underline;
      }
      code {
        background: #e7e8e2;
        border-radius: 5px;
      }
      em {
        font-style: italic;
        filter: brightness(120%);
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
      .remark-code-line-highlighted     { background-color: #373832; }
      .pull-left {
        float: left;
        width: 47%;
      }
      .pull-right {
        float: right;
        width: 47%;
      }
      .pull-right ~ p {
        clear: both;
      }
      #slideshow .slide .content code {
        font-size: 0.8em;
      }
      #slideshow .slide .content pre code {
        font-size: 0.9em;
        padding: 15px;
      }
      .inverse {
        background: #242424;
        color: #9e9e9e;
        text-shadow: 0 0 20px #333;
      }
      .inverse h1, .inverse h2 {
        color: #f3f3f3;
        line-height: 1em;
      }


      /* Slide-specific styling */
      #slide-inverse .footnote {
        bottom: 12px;
        left: 20px;
      }
      #slide-how .slides {
        font-size: 0.9em;
        position: absolute;
        top:  151px;
        right: 140px;
      }
      #slide-how .slides h3 {
        margin-top: 0.2em;
      }
      #slide-how .slides .first, #slide-how .slides .second {
        padding: 1px 20px;
        height: 90px;
        width: 120px;
        -moz-box-shadow: 0 0 10px #777;
        -webkit-box-shadow: 0 0 10px #777;
        box-shadow: 0 0 10px #777;
      }
      #slide-how .slides .first {
        background: #fff;
        position: absolute;
        top: 20%;
        left: 20%;
        z-index: 1;
      }
      #slide-how .slides .second {
        position: relative;
        background: #fff;
        z-index: 0;
      }

      /* Two-column layout */
      .left-column {
        color: #777;
        width: 20%;
        height: 92%;
        float: left;
      }
        .left-column h2:last-of-type, .left-column h3:last-child {
          color: #000;
        }
      .right-column {
        width: 75%;
        float: right;
        padding-top: 1em;
      }
    </style>
  </head>
  <body>
    <textarea id="source">

    name: inverse
    layout: true
    class: center, middle, inverse
    ---

    # Risk for Engineers
    ### Measuring the reduction of "_bad things_" in our future

    ---

    ## Problem:

    --

    ### I build security things, but I can't measure what difference it made.

    ---

    ## This method is simple and powerful.

    ---

    ## In fact, you're going to measure a risk *right now*.

    ---

    ## It's our "Hello World".

    ---

    ## Think of a *big* risk that you _recently_ tried to mitigate.

    ---
    name: final
    layout: true
    class: left, top, inverse
    ---

    ## Examples:

    --

    ### Customer data is stolen.

    --

    ### Our CEO has malware on their laptop

    --

    ### We are knocked offline because of an incident.

    ---
    template: inverse
    layout: true
    ---

    ## Now, ask yourself:

    ---

    ## 1. Will this occur this year?

    --

    ## 2. What are the odds that it will?

    ---

    ## You don't have to worry about correct answers yet.

    --

    ### In fact, being "correct" might not matter.

    ---

    ### That part is most important, you'll soon understand why.

    ---

    ## Here's an example scenario.

    ---
    ## Scenario:
    ### We are knocked offline because of an incident in the next year.
    ---
    ## Your forecast:
    ### There is a .red[33% chance] that this will happen.

    ---

    ## You're done!
    ### That's it. We have successfully forecasted a risk.

    ---

    ## But this data is .red[worthless] unless we know how to use it.

    --

    ### Be skeptical!

    --

    ### This forecast has lots of problems.

    ---
    template: final
    layout: false
    ## Why?

    --

    ### People are highly biased with guesses. [Research](https://machinelearnings.co/why-are-we-so-confident-2c3151a6d5d0) agrees.

    --

    ### A [decade of research](https://www.amazon.com/Expert-Political-Judgment-Good-Know/dp/0691128715) shows experts to be hilariously weak at predictions.

    --

    ### Risk involves the probability of future events.

    --

    ### As "experts", we are also .red[worse] at predicting risks.

    ---
    template: inverse
    layout: true
    ---

    ### This may be one of the reasons we are so bad at preventing breaches.

    ---

    ### By default, we are weak at predictions, and worse at measuring risk.

    ---

    ## This issue is rampant in our industry.

    ---

    ### But there's hope!

    ---

    ## High risk industries rely on probabilistic approaches to risk.

    --

    ### [Space](https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20120001369.pdf), [Nuclear](https://www.nrc.gov/about-nrc/regulatory/risk-informed/pra.html), [Oil](https://www.bsee.gov/sites/bsee.gov/files/interagency-agreements-mous-moas//nasa-bsee-iaa-1-28-16.pdf), [Environmental](https://www.epa.gov/risk/policy-use-probabilistic-analysis-risk-assessment-epa)

    --

    ## For some reason, we haven't been.

    ---

    ## Forecasting fills in the gaps where "_We don't have data!_"

    --

    ### It turns out, this is not a valid excuse in any other industry.

    ---

    ## It's easy to mimic the habits of [effective forecasters](https://www.amazon.com/Superforecasting-Science-Prediction-Philip-Tetlock-ebook/dp/B00RKO6MS8).

    ---

    ## These methods are easy to copy, with measurable results.

    ---

    ### This means rigorous forecasts can be relied on for decisions.

    --

    ### That .red[33%] value can become a meaningful decision making tool...

    --

    ### ...instead of feeling like a guess.

    ---

    # How do we fix our forecast?

    ---

    ### The forecast needs _discipline_ to increase the value of the _forecaster_.

    ---

    ### Let's build that process.

    ---

    ## First, let's review another simple example.

    ---

    # An employee is infected with malware.
    ### üíªÔ∏è

    ---
    ### You predict...
    ## There is a .red[15%] chance that this will happen.

    ---

    ### We require _rigor_ to take this seriously.

    ---

    ### It's not specific enough to forecast. Let's time box it to "this year".

    --

    ## Pick a timeframe.

    ---

    ### Add threat, vector, asset, when you can. These improve for future forecasts.

    --

    ## Be less ambiguous.

    ---
    ### Some examples:

    ---
    ## A C-Level executive is infected with malware in the next quarter.
    ---
    ## An employee is infected by an email attachment, resulting in a .red[SEV1] incident this year.
    ---
    ## Compromised employees are discovered by malware discovered as a result of next week's C&C hunt.
    ---

    ### These are better, but they don't have to be perfect.

    --

    ### Picking a good scenario is a lot like agreeing on a problem.

    --

    ## Nearly any future event can be forecasted.

    ---

    ### Also:

    ---

    ### A well designed scenario is vulnerable to [Fermi's methods](https://en.wikipedia.org/wiki/Fermi_problem) of decomposition.

    ---

    ### We want to break down any available measurable data about the scenario.

    --

    ### Previous metrics, similar forcasts, historical data, industry data, etc.

    --

    ## A forecast improves with any data, _even just a little_.

    ---

    ### Next, we improve the forecaster.

    --

    ## We calibrate the forecaster's sense of certainty.

    ---

    ### This fixes problems with forecasting bias.

    ---

    ### It helps us avoid overconfidence.
    ### It focuses our personal "certainty" about information.

    --

    ## It becomes simple to assign numbers to our certainty.

    ---
    ### You can quickly sample your own skills [here](http://confidence.success-equation.com), or [here](http://sethrylan.org/bayesian/calibrate.html).
    ---
    ### Go do this, then come back.
    ---
    ## Welcome back!
    ### [Recent studies](https://hbr.org/2016/05/superforecasting-how-to-upgrade-your-companys-judgment) show that minimal training will drastically improve forecasting abilities.
    ---
    ## That means you just practiced a little.
    ---
    ## That also means your forecasts are now more reliable.
    ---
    ## We can improve this even *more*.
    ---
    ## Let's remove bias from our forecast.
    ### You'd grab some friends, co-workers, experts, etc. Diverse is better.
    ---
    ## Then, we'd calibrate them, too.
    ###<i class="fa fa-user" aria-hidden="true"></i> <i class="fa fa-user" aria-hidden="true"></i> <i class="fa fa-user" aria-hidden="true"></i> <i class="fa fa-user" aria-hidden="true"></i> <i class="fa fa-user" aria-hidden="true"></i>

    --

    ### Now we can average them together into one forecast:

    --

    ### <i class="fa fa-user" aria-hidden="true"></i>

    ---
    ### Groups seem to benefit greatly from combined forecasts.
    ---
    ## A fun example.

    --

    ### In 1907, a group of 787 people [correctly guessed the weight of an Ox](https://arxiv.org/pdf/1410.3989.pdf).

    --

    .footnote[see [The Wisdom of Crowds](https://en.wikipedia.org/wiki/The_Wisdom_of_Crowds)]


    ---

    ## A recent example.

    --

    ### This method was used to combine civilian [forecasters into teams](https://www.npr.org/sections/parallels/2014/04/02/297839429/-so-you-think-youre-smarter-than-a-cia-agent)...

    --

    ### ...who .red[beat] national security intelligence analysts...

    --

    ###...who had access to .red[confidential data].

    ---

    ### So, where are we?

    --

    ## Lets summarize.

    ---

    name: final
    layout: true
    class: left, top, inverse

    ---

    # We have forecasting tools.

    --

    ### Forecasts are improved with specific, time boxed scenarios.

    --

    ### Groups of diverse expert forecasts can smoothen out bias, like FUD and overconfidence.

    --

    ### We can be trained to calibrate ourselves. [Quickly](http://journal.sjdm.org/16/16511/jdm16511.pdf).

    --

    ### So...

    --

    ## Calibrated experts can forecast the probability of a risk.

    ---
    template: inverse
    layout: true
    ---

    ## We're still not done.

    --

    ### This is *still not useful*.

    ---

    ### We have improved our ability to forecast, but who says we can actually predict the future?

    ---

    ### We can't.

    ### We can't know what future is written in the cosmic notebook.

    ### üååüßô‚Äç‚ôÇÔ∏è‚Äçüìñüßô‚Äç‚ôÄÔ∏èüåå

    ---

    ## There is an _actual_ probibility we don't see.

    ---

    ## Some events we need to forecast cannot be tracked afterwards.

    ---

    ### There are _oracles_ we don't get to see.

    ---

    ## We have to work without access to it.

    ---

    ## With these methods,
    ## we're not pretending to find that number.

    ---

    ### We're not trying to find a bullseye.

    --

    ### We're just trying to get measurably closer to one.

    ---

    ## This is a matter of accuracy versus *precision*.

    --

    ### Accuracy needs to be close to the true probability.
    --

    ### We'll never know if we succeeded.

    ---

    ### Precision is about reliably creating the same result, even if we're off-center.

    ---

    ### To put this simply...

    --

    ## We may never find the cosmic "bullseye".

    --

    ## Instead, we can track progress towards it.

    --

    ## üéØ

    ---
    template: final
    layout: true
    ---
    ## Reducing probabilistic risk over time:
    Scenario: _"Attacker obtains keys for destructive AWS IAM permissions in the next 365 days."_

    --

    Let's run forecasts every quarter while we mitigate this risk.

    --

    ### 2016 - Q3: .red[25%]

    --

    ### 2016 - Q4: .red[23%]

    --

    ### 2017 - Q1: .red[16%]

    --

    ### 2017 - Q2: .green[10%]

    --

    ## An increase in confidence against this threat of .green[15%].

    --

    ## We have measured better .green[good] outcomes over .red[bad].

    ---

    ## Directionality of confidence is all that matters.

    --

    ### It is impossible to read the oracle of probability for each risk.

    --

    ### If our efforts mitigate risk, we believe we influence these "oracles".

    --

    ### Then our forecasts of risk likely share a direction with an unknown oracle.

    --

    ## If there is truth to this, then we have a huge opportunity...

    ---
    template: inverse

    ## We can measure that we're getting better at security.
    .footnote[These slides are paired up with this [article](https://medium.com/starting-up-security/killing-chicken-little-measure-and-eliminate-risk-through-forecasting-ecdf4c7e9575).]

    </textarea>
        <script src="https://remarkjs.com/downloads/remark-latest.min.js">
    <script>
      var hljs = remark.highlighter.engine;
    </script>
    <script src="remark.language.js"></script>
    <script>
      var slideshow = remark.create({
          highlightStyle: 'monokai',
          highlightLanguage: 'remark',
          highlightLines: true
        }) ;
    </script>
    <script>
      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-44561333-1']);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script');
        ga.src = 'https://ssl.google-analytics.com/ga.js';
        var s = document.scripts[0];
        s.parentNode.insertBefore(ga, s);
      }());
    </script>
  </body>
</html>
